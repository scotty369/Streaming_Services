```{python}
import pandas as pd
import plotly.express as px
import polars as pl

# Load datasets
disney = pl.read_csv("/Users/scotttow123/Documents/Streaming_Services/Data/disney_plus_titles.csv")
hulu = pl.read_csv("/Users/scotttow123/Documents/Streaming_Services/Data/hulu_titles.csv")
netflix = pl.read_csv("/Users/scotttow123/Documents/Streaming_Services/Data/netflix_titles.csv")
prime = pd.read_csv("/Users/scotttow123/Documents/Streaming_Services/Data/amazon_prime_titles.csv")

# Convert Polars DataFrames to Pandas DataFrames for ease of use
disney = disney.to_pandas()
hulu = hulu.to_pandas()
netflix = netflix.to_pandas()

# Add platform column
disney['platform'] = 'Disney+'
hulu['platform'] = 'Hulu'
netflix['platform'] = 'Netflix'
prime['platform'] = 'Amazon Prime'

# Combine datasets
data = pd.concat([disney, hulu, netflix, prime], ignore_index=True)

# Inspect the data
print(data.head())
print(data.info())  # Check for missing values and data types
```

```{python}
# Check for missing values
print(data.isnull().sum())

# Drop rows with missing data
data = data.dropna(subset=['release_year', 'duration', 'type'])

# Inspect the cleaned data
print(data.head())

```

```{python}
# One-hot encode the 'platform' column
data = pd.get_dummies(data, columns=['platform'], drop_first=True)

# Convert 'release_year' and 'duration' to numerical values
# Convert duration from string to numeric (e.g., "90 min" to 90)
data['duration'] = data['duration'].apply(lambda x: int(str(x).replace(' min', '').strip()) if isinstance(x, str) else x)

# Check for any remaining missing data after processing
print(data.isnull().sum())

```

```{python}
from sklearn.model_selection import train_test_split

# Define features (X) and target (y)
X = data.drop('type', axis=1)  # Features: all columns except 'type'
y = data['type']  # Target variable: 'type' (Movie or TV Show)

# Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

```

```{python}
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix

# Initialize the RandomForestClassifier model
model = RandomForestClassifier(random_state=42)

# Train the model
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

```

```{python}
from sklearn.model_selection import GridSearchCV

# Set up parameter grid for hyperparameter tuning
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [10, 20, 30],
    'min_samples_split': [2, 5, 10]
}

# Initialize GridSearchCV
grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42), param_grid=param_grid, cv=3)

# Fit the model with GridSearchCV
grid_search.fit(X_train, y_train)

# Print the best parameters
print(f"Best Parameters: {grid_search.best_params_}")

```

```{python}
```

```{python}
```

```{python}
```

```{python}
```

```{python}
```

```{python}
```

```{python}
```

